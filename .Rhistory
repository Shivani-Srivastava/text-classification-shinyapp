source("https://raw.githubusercontent.com/sudhir-voleti/basic-text-analysis-shinyapp/master/dependency-basic-text-analysis-shinyapp.R")
runGitHub("basic-text-analysis-shinyapp","sudhir-voleti")
source("https://raw.githubusercontent.com/sudhir-voleti/basic-text-analysis-shinyapp/master/dependency-basic-text-analysis-shinyapp.R")
runGitHub("basic-text-analysis-shinyapp-1","yogesh1612")
source("https://raw.githubusercontent.com/sudhir-voleti/basic-text-analysis-shinyapp/master/dependency-basic-text-analysis-shinyapp.R")
runGitHub("basic-text-analysis-shinyapp","sudhir-voleti")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("readtext")
library("readtext")
df <- readtext("data/Amazon - Fire.csv")
View(df)
class(df)
str(df)
runApp()
runApp()
textclassif_nb <- function(test_csv, # input file with text and Y colms
y_n0,     # position of Y colm in the input DF. Need user-input
x_n0,     # position of X or text colm. User input
trg_propn = 0.70,   # default and slider for user input
n00 = 20){   # num_term coeffs to display for each class
x = test_csv[, x_n0]
y = test_csv[, y_n0]
# building DFM
test_corpus <- corpus(x) # constructing a corpus
dfm_test = test_corpus %>% tokens(., remove_punct = TRUE) %>% # tokenize
tokens_select(., pattern = stopwords("en"), selection = "remove") %>% # pre-proc
dfm(.) %>% dfm_trim(., min_termfreq = 5)  # build DFM
# generate 70% sample for training, sample numbers without replacement
train_n0 = trg_propn*nrow(dfm_test) %>% round(.,0); train_n0
id_train = sample(seq(1:nrow(dfm_test)), train_n0, replace = FALSE); length(id_train)
id_test = as.matrix(seq(1:nrow(dfm_test)))[-id_train, 1]; length(id_test)
test_corpus$id_numeric <- 1:ndoc(test_corpus) # create docvar with ID
# get training & test sets
dfm_training <- test_corpus %>% corpus_subset(., id_numeric %in% id_train) %>%
tokens(., remove_punct = TRUE) %>%
dfm(., remove = stopwords("en"), stem = TRUE)
dfm_test <- test_corpus %>% corpus_subset(., !id_numeric %in% id_train) %>%
tokens(., remove_punct = TRUE) %>%
dfm(remove = stopwords("en"), stem = TRUE)
## Train the naive Bayes classifier using textmodel_nb().
tmod_nb <- textmodel_nb(dfm_training, y[id_train])
#summary(tmod_nb)
dfm_matched <- dfm_match(dfm_test, features = featnames(dfm_training))  # match tokens from trg & test DFMs
actual_class <- y[id_test]; length(actual_class)  # Y value must be taken based on user-input or default
predicted_class <- predict(tmod_nb, newdata = dfm_matched); # head(predicted_class)
tab_class <- table(actual_class, predicted_class); # tab_class  # confusion matrix
if (nrow(tab_class) == ncol(tab_class)){ outp0 = confusionMatrix(tab_class, mode = "everything")
} else {outp0 = tab_class}
outp0  # output for display in app
# display feature based results
classif_probs = tmod_nb$param # dim(tmod_nb$param)
list00 = vector(mode = "list", length = nrow(classif_probs))
# n00 = 20 # top n00 terms that impact a class to be displayed => from user input
for (i0 in 1:nrow(classif_probs)){
a00 = classif_probs[i0,]; head(a00)
a01 = sort(a00, decreasing = TRUE, index.return=TRUE)
a02 = a00[a01$ix[1:n00]]
df00 = data.frame( tokens = names(a02)[1:n00], proby = round(a02[1:n00], 3))
rownames(df00) = NULL
colnames(df00) = sapply(colnames(df00), function(x) {paste0(x, "_", i0)}) %>% as.character(.)
list00[[i0]] = df00      } # i0 loop ends
df0 = as.data.frame(list00); df0  # this becomes output for display
return(list(outp0, list00)) }
View(df)
op<-textclassif_nb(df,y_n0 = df$text,x_n0 = df$review,trg_propn = 0.70,n00 = 20)
cols <- colnames(df)
y_n0<-match("text",cols)
y_n0
x_n0 <- match("review",cols)
op<-textclassif_nb(df,y_n0 = match("text",cols),x_n0 = match("review",cols),trg_propn = 0.70,n00 = 20)
op[[1]]
op[[2]]
## Only run examples in interactive R sessions
if (interactive()) {
# basic example
shinyApp(
ui = fluidPage(
selectInput("variable", "Variable:",
c("Cylinders" = "cyl",
"Transmission" = "am",
"Gears" = "gear")),
tableOutput("data")
),
server = function(input, output) {
output$data <- renderTable({
mtcars[, c("mpg", input$variable), drop = FALSE]
}, rownames = TRUE)
}
)
# demoing group support in the `choices` arg
shinyApp(
ui = fluidPage(
selectInput("state", "Choose a state:",
list(`East Coast` = list("NY", "NJ", "CT"),
`West Coast` = list("WA", "OR", "CA"),
`Midwest` = list("MN", "WI", "IA"))
),
textOutput("result")
),
server = function(input, output) {
output$result <- renderText({
paste("You chose", input$state)
})
}
)
}
x <- colnames(df)
x[-sel_x]
sel_x <- "text"
x[-sel_x]
x[,-sel_x]
x[sel_x]
match(sel_x,x)
x[-2]
runApp()
library("quanteda.textplots")
install.packages("quanteda.textplots")
library("quanteda.textplots")
install.packages("quanteda.textplots")
install.packages("quanteda.textplots")
library("quanteda.textplots")
dfm <- corpus(df$review) %>%
dfm(remove = stopwords('english'), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 10, verbose = FALSE)
set.seed(100)
textplot_wordcloud(dfm)
str(df)
corpus_subset(df$review,
text %in% c(unique(df$text)) %>%
dfm(groups = "President", remove = stopwords("english"), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 5, verbose = FALSE) %>%
textplot_wordcloud(comparison = TRUE))
text_corpus <- corpus(df$review)
corpus_subset(text_corpus,
text %in% c(unique(df$text)) %>%
dfm(groups = "President", remove = stopwords("english"), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 5, verbose = FALSE) %>%
textplot_wordcloud(comparison = TRUE))
corpus_subset(text_corpus,
text %in% c(unique(df$text))
)
data_corpus_inaugural
t <- data_corpus_inaugural
text_corpus <- corpus(df)
text_corpus <- corpus(df,text_field = df$review)
text_corpus <- corpus(df,text_field = review)
text_corpus <- corpus(df,text_field = 'review')
corpus_subset(text_corpus,
text %in% c(unique(df$text))
)
corpus_subset(text_corpus,
text %in% c(unique(df$text)) %>%
dfm(groups = "text", remove = stopwords("english"), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 5, verbose = FALSE) %>%
textplot_wordcloud(comparison = TRUE))
df$text <- as.character(df$text)
text_corpus <- corpus(df,text_field = 'review')
corpus_subset(text_corpus,
text %in% c(unique(df$text)) %>%
dfm(groups = "text", remove = stopwords("english"), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 5, verbose = FALSE) %>%
textplot_wordcloud(comparison = TRUE))
text
text_corpus
View(df)
df <- readtext("data/Amazon - Fire.csv")
View(df)
df <- readtext("data/Amazon - Fire.csv",text_field = "review")
dfm <- corpus(df$review) %>%
dfm(remove = stopwords('english'), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 10, verbose = FALSE)%>%textplot_wordcloud(comparison = TRUE))
dfm <- corpus(df$review) %>%
dfm(remove = stopwords('english'), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 10, verbose = FALSE)
textplot_wordcloud(dfm)
df <- read.csv("data/Amazon - Fire.csv")
str(df)
dfm <- corpus(df$review) %>%
dfm(remove = stopwords('english'), remove_punct = TRUE) %>%
dfm_trim(min_termfreq = 10, verbose = FALSE)
set.seed(100)
textplot_wordcloud(dfm,color = c('red', 'pink', 'green', 'purple', 'orange', 'blue'))
shinyWidgets::shinyWidgetsGallery()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
df <- read.csv("data/Amazon - Fire.csv")
View(df)
ol<- textclassif_nb(df, # input file with text and Y colms
"stars",     # position of Y colm in the input DF
"review",     # position of X or text colm
trg_propn = 0.70,   # default and slider for user input
n00 = 100)   # num_term coeffs to display for each class
ol[[1]]
as.data.frame(ol[[1]])
class(ol[[1]])
runApp()
ol[[2]]
names(ol)<- unique(df$stars)
names(ol)
names(ol[[1]])
names(ol[[2]])
ol[[2]]
length(ol[[2]])
ol[[2]][[1]]
runApp()
runApp()
runApp()
textclassif_nb <- function(test_csv, # input file with text and Y colms
y_n0,     # position of Y colm in the input DF. Need user-input
x_n0,     # position of X or text colm. User input
trg_propn = 0.70,   # default and slider for user input
n00 = 20,
model="nb"){   # num_term coeffs to display for each class
x = test_csv[, x_n0]
y = test_csv[, y_n0]
# building DFM
test_corpus <- corpus(x) # constructing a corpus
dfm_test = test_corpus %>% tokens(., remove_punct = TRUE) %>% # tokenize
tokens_select(., pattern = stopwords("en"), selection = "remove") %>% # pre-proc
dfm(.) %>% dfm_trim(., min_termfreq = 5)  # build DFM
# generate 70% sample for training, sample numbers without replacement
train_n0 = trg_propn*nrow(dfm_test) %>% round(.,0); train_n0
id_train = sample(seq(1:nrow(dfm_test)), train_n0, replace = FALSE); length(id_train)
id_test = as.matrix(seq(1:nrow(dfm_test)))[-id_train, 1]; length(id_test)
test_corpus$id_numeric <- 1:ndoc(test_corpus) # create docvar with ID
# get training & test sets
dfm_training <- test_corpus %>% corpus_subset(., id_numeric %in% id_train) %>%
tokens(., remove_punct = TRUE) %>%
dfm(., remove = stopwords("en"), stem = TRUE)
dfm_test <- test_corpus %>% corpus_subset(., !id_numeric %in% id_train) %>%
tokens(., remove_punct = TRUE) %>%
dfm(remove = stopwords("en"), stem = TRUE)
## Train the naive Bayes classifier using textmodel_nb().
if(model=="nb"){
tmod_nb <- textmodel_nb(dfm_training, y[id_train])
}
if(model=="lr"){
tmod_nb <- textmodel_lr(dfm_training, y[id_train])
}
#summary(tmod_nb)
dfm_matched <- dfm_match(dfm_test, features = featnames(dfm_training))  # match tokens from trg & test DFMs
actual_class <- y[id_test]; length(actual_class)  # Y value must be taken based on user-input or default
predicted_class <- predict(tmod_nb, newdata = dfm_matched); # head(predicted_class)
tab_class <- table(actual_class, predicted_class); # tab_class  # confusion matrix
if (nrow(tab_class) == ncol(tab_class)){ outp0 = confusionMatrix(tab_class, mode = "everything")
} else {outp0 = tab_class}
outp0  # output for display in app
# display feature based results
classif_probs = tmod_nb$param # dim(tmod_nb$param)
list00 = vector(mode = "list", length = nrow(classif_probs))
# n00 = 20 # top n00 terms that impact a class to be displayed => from user input
for (i0 in 1:nrow(classif_probs)){
a00 = classif_probs[i0,]; head(a00)
a01 = sort(a00, decreasing = TRUE, index.return=TRUE)
a02 = a00[a01$ix[1:n00]]
df00 = data.frame( tokens = names(a02)[1:n00], proby = round(a02[1:n00], 3))
rownames(df00) = NULL
colnames(df00) = sapply(colnames(df00), function(x) {paste0(x, "_", i0)}) %>% as.character(.)
list00[[i0]] = df00      } # i0 loop ends
df0 = as.data.frame(list00); df0  # this becomes output for display
return(list(outp0, list00)) }
ol<- textclassif_nb(df, # input file with text and Y colms
"stars",     # position of Y colm in the input DF
"review",     # position of X or text colm
trg_propn = 0.70,   # default and slider for user input
n00 = 100,
model="nb")   # num_term coeffs to display for each class
ol<- textclassif_nb(df, # input file with text and Y colms
"stars",     # position of Y colm in the input DF
"review",     # position of X or text colm
trg_propn = 0.70,   # default and slider for user input
n00 = 100,
model="lr")   # num_term coeffs to display for each class
?textmodel_lr()
ol[[1]]
ol[[1]][[2]]
ol[[1]][[1]]
ol[[1]][[3]]
ol[[1]][[3]][[1:2]]
ol[[1]][[3]][1:3]
ol[[1]][[3]]
ol[[1]]
runApp()
runApp()
runApp()
runApp()
ol[[1]][[1]]
ol[[1]]
ol[[1]][1]
ol[[1]]$table
runApp()
ol[[1]][2]
ol[[1]][[2]]
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
ol[[1]]
ol[[2]]
ol[[2]][1]
ol[[2]][1][,1:20]
ol[[2]][1][1:20]
class(ol[[2]][1])
as.data.frame(ol[[2]][1])
i <- '1'
ol[[2]][as.numeric(i)]
runApp()
runApp()
